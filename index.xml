<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>bachase notes</title>
<link>https://bachase.github.io/</link>
<atom:link href="https://bachase.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>bachase&#39;s notes on things he&#39;s learning about</description>
<generator>quarto-1.7.34</generator>
<lastBuildDate>Wed, 10 Sep 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Profiling Quantum Compilers: Qiskit</title>
  <link>https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/</link>
  <description><![CDATA[ 




<p>This post is the first follow-up in the quantum compiler profiling <a href="posts/profiling-quantum-compilers/">series</a>, focusing on Qiskit version 2.1.1. Let’s dive right in!</p>
<section id="overview" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>We begin with a top-level view of the compilation (or transpilation in Qiskit lingo). This took a total of 1.04 seconds. You can inspect this function-aggregated view in speedscope <a href="https://www.speedscope.app/#profileURL=https%3A%2F%2Fraw.githubusercontent.com%2Fbachase%2Fquantum-compiler-profiling%2Frefs%2Fheads%2Fmain%2Fnative.functionagg.profiles%2Fqiskit.profile.json&amp;title=Qiskit%20Profile%20FunctionAgg">here</a>. <img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/qiskit_top_level.png" class="img-fluid"></p>
<p>I’ve labeled the 3 primary calls within the profiling function</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> run_qiskit(qasm):</span>
<span id="cb1-2">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> qiskit <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> QuantumCircuit, transpile <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1)</span></span>
<span id="cb1-3">    circuit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> QuantumCircuit.from_qasm_str(qasm) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2)</span></span>
<span id="cb1-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> transpile(                            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3)</span></span>
<span id="cb1-5">        circuit, basis_gates<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rz"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rx"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ry"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"h"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cx"</span>], optimization_level<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb1-6">    )</span></code></pre></div>
<div class="no-bullets">
<ul>
<li><span class="circle">1</span> [39%, 410ms] The call tree starting from <code>_find_and_load</code> importing Qiskit.</li>
<li><span class="circle">2</span> [29%, 300ms] in <code>from_qasm_str</code> parsing the 25K line QASM file into Qiskit’s in-memory circuit representation.</li>
<li><span class="circle">3</span> [25%, 260ms] in <code>transpile</code> actually optimizing the circuit.</li>
</ul>
</div>
<p>Let’s dig in a bit more.</p>
<section id="import" class="level3">
<h3 class="anchored" data-anchor-id="import"><code>import</code></h3>
<p>Almost 40% of this run is on imports! I suspect this will be similar for most libraries we profile, as there is a lot of dynamic importing and logic these libraries are doing to support different features, lazily load some more complex dependencies etc. I’m not going to explore which import(s) are taking all this time but a good bit comes from Qiskit itself importing numpy as seen in the sandwich view here: <img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/numpy_import.png" class="img-fluid"></p>
<p>But I do want to highlight this overhead is meaningful for users! For interactive sessions like notebooks you only pay for this once, but in scripts (CI tests etc), you pay for this each time the script is run. This might explain the appeal of languages like Rust, where most of this is resolved at compile time.</p>
<p>For diving deeper, checkout <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-11-how-the-python-import-system-works/">this</a> old but still solid reference on what Python does when you type <code>from package import foo</code>.</p>
</section>
<section id="parsing-qasm" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="parsing-qasm">Parsing QASM</h3>
<p>Next up is <code>from_qasm_str</code>, which takes 30% of the overall runtime. For this exploration, I switched to the non-function aggregated sampling (speedscope <a href="https://www.speedscope.app/#profileURL=https%3A%2F%2Fraw.githubusercontent.com%2Fbachase%2Fquantum-compiler-profiling%2Frefs%2Fheads%2Fmain%2Fnative.profiles%2Fqiskit.profile.json&amp;title=Qiskit%20Profile">here</a>) because functions like <code>from_bytecode</code> are pretty lengthy. We want to know specifically where inside that function the code is spending time, which is lost with function aggregation. Looking at the sandwich view around <code>from_qasm_str</code> we have some structure</p>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/loads.png" class="img-fluid"></p>
<p>For <span class="circle">1</span> <code>loads</code> itself is defined in <a href="https://github.com/Qiskit/qiskit/blob/6dd1267466e6effb9b1a60e98ecaae1ac718e5b2/qiskit/qasm2/__init__.py#L578"><code>qasm2/__init__.py</code></a>, reproduced in part here</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> loads(...):</span>
<span id="cb2-2">    custom_instructions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(custom_instructions)</span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> _parse.from_bytecode(</span>
<span id="cb2-4">        _qasm2.bytecode_from_string(</span>
<span id="cb2-5">            string,</span></code></pre></div>
<p><code>_qasm2.bytecode_from_string</code> calls directly into Rust to generate some bytecode representation<sup>1</sup> of the parsed QASM that must be easier to manage, and probably is a simpler post-validated representation. But importantly, that call itself doesn’t show up in any samples, so it must be pretty fast.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://en.wikipedia.org/wiki/Bytecode">Bytecode</a> is an instruction set oriented view of a program that simplifies processing by an interpreter. Python itself compiles your code (at execution time) to bytecode before it is run by the Python interpreter. QASM doesn’t have an official bytecode specification, but converting it to bytecode before interpreting is a good strategy to separate parsing + validation from the downstream use.</p></div></div><p>For <span class="circle">2</span> and <span class="circle">3</span>, the samples we have are all in <code>_parse.from_bytecode</code>, where the bytecode is used to construct the in-memory circuit. The two spots are nearby lines <a href="https://github.com/Qiskit/qiskit/blob/6dd1267466e6effb9b1a60e98ecaae1ac718e5b2/qiskit/qasm2/parse.py#L254">here</a></p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> op <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> bytecode:</span>
<span id="cb3-2">    ...</span>
<span id="cb3-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> opcode <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> OpCode.Gate:</span>
<span id="cb3-4">            gate_id, parameters, op_qubits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> op.operands <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2)</span></span>
<span id="cb3-5">            qc._append(</span>
<span id="cb3-6">                CircuitInstruction(gates[gate_id](<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>parameters),</span>
<span id="cb3-7">                [qubits[q] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> q <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> op_qubits]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3)</span></span>
<span id="cb3-8">            )</span>
<span id="cb3-9">    ...</span></code></pre></div>
<p>Look at the functions called from these lines, that first <code>__init__</code> is the initializer for an <code>Rz</code> gate, <code>_append</code> is adding a newly created gate to <code>QuantumCircuit</code>, and <code>params</code> is both setting and adding a parameter to the quantum instruction representing a gate. Almost all the hex addresses <span class="circle">4</span> are calls inside the CPython/libpython shared object file, but I didn’t have debug symbols around to know what they are. But down in <span class="circle">5</span>, we see calls into the Qiskit Rust code to create the Rust instances of these circuit instructions that are then wrapped in Python. I’m not familiar yet with Qiskit internals, but there will always be some overhead to go back and forth to Rust to create each gate instance.</p>
<p>I don’t have any deep insights, but am interested to see the parsing performance of other libraries. It’s also interesting to see the mix of Python and Rust in Qiskit, where the initial bytecode parse is super fast, but there is still work to improve the in-memory construction of circuit representations afterwards.</p>
</section>
<section id="compiling-aka-transpiling" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="compiling-aka-transpiling">Compiling (aka Transpiling)</h3>
<p>Ok, finally showtime! Again, we return to the sandwich view. Note that this is “left-heavy” within the view, meaning the calls show are not time-ordered, but shifted left by longest call.</p>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/transpile.png" class="img-fluid"></p>
<p>Qiskit has a sophisticated <a href="https://quantum.cloud.ibm.com/docs/en/guides/transpile-with-pass-managers">PassManager class</a> for specifying the transpilation passes to run. Our example code here used the default passes with the highest optimization setting. The <code>_run_workflow</code> and <code>execute</code> calls in the callstack are the machinery to dispatch the different passes. But the actual work is done in a specific pass <code>run</code> function. The level 3 passes are defined <a href="https://github.com/Qiskit/qiskit/blob/6dd1267466e6effb9b1a60e98ecaae1ac718e5b2/qiskit/transpiler/preset_passmanagers/level3.py#L27">here</a>, but only two stand out in the profiling results <sup>2</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Note that the results shown here were sampled at 100 times per second, meaning each sample is 10 milliseconds. This transpile section was ~250ms, so we have 25 samples. The limiting sampling factor was the GitHub workspace machine, which had trouble keeping up at a higher rate (but which I used to get access to native stack trace details). I did run locally with 1000 times per second sampling (but no native symbol support on my Mac), which showed similar time spent in these functions.</p></div></div><section id="minimumpoint" class="level4">
<h4 class="anchored" data-anchor-id="minimumpoint">MinimumPoint</h4>
<p><span class="circle">1</span> is part of the <a href="https://github.com/Qiskit/qiskit/blob/6dd1267466e6effb9b1a60e98ecaae1ac718e5b2/qiskit/transpiler/passes/utils/minimum_point.py#L100"><code>MinimumPoint</code></a> transformation pass. This is used by other iterative passes to see if successive runs have improved some circuit metrics. It was hard to infer what these passes were from the sampled callstacks, so I instead put a breakpoint in the debugger to take a peek when the MinimumPoint class was constructed. I walked up the stack to see the passmanager this is part of and found: <img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/optimization_passes.png" class="img-fluid"> So this pass group is running a bunch of optimization passes, and this <code>MinimumPoint</code> class is checking when it’s converged to a local minimum “best” for depth and size. But the heavy part here is all in one line</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ...</span></span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> state.score:</span>
<span id="cb4-3">    state.since <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-4">    state.score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> score</span>
<span id="cb4-5">    state.dag <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deepcopy(dag) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#&lt;-- this one</span></span></code></pre></div>
<p>Once a better score is reached, a full copy of the entire DAG is captured. You can scroll below in speedscope to see all the calls this results in.</p>
<p>Given the Python object model, a true independent copy of an object requires copying each internal object as well. This is expensive because Python variables are fundamentally references (pointers) to objects in memory. A simple (or “shallow”) copy of the DAG would just create a new list of pointers to the exact same gate objects. Modifying a gate in the new DAG would also modify it in the old one.</p>
<p><code>deepcopy</code>, in contrast, must recursively walk the entire object graph—visiting every single gate, parameter, and qubit reference—and create a brand-new, independent Python object for each one. This process involves a massive number of new object allocations and reference lookups, all managed by the Python interpreter, making it far slower than a single, contiguous memory copy you might see in a language like C.</p>
<p>For this large circuit, it’s a heavy operation. If the IR were represented in Rust with a less pointer-heavy structure (like a more flat memory layout), it could be possible to optimize this. But I’m guessing this is complex as long as parts of the IR are still managed as Python objects at a granular level, versus entirely represented in Rust.</p>
</section>
<section id="commutative-cancellation" class="level4">
<h4 class="anchored" data-anchor-id="commutative-cancellation">Commutative Cancellation</h4>
<p><span class="circle">2</span> is the other heavy pass spot, with two call stacks corresponding to <code>commutative_cancellation</code> which is (unsurprisingly) a Rust-accelerated pass that uses commutation relations to identify cancellation opportunites between gates. I haven’t tried compiling the Rust components of Qiskit with debug symbols to get the locations within the Rust code directly. But for the longer 30ms call (3 samples), 20 ms (2 samples) are taken when releasing memory in <code>free</code>. In the other, 10 ms (1 sample) of the 20ms are spent hashing, which I assume is a lookup for common gate pairs.</p>
<p>If you look in the time-ordered view you see there are two commutative cancellation pass runs surrounding the minimum point call. Perhaps there could be savings by retaining the analysis or hash lookup across calls.</p>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/commutative_cancel.png" class="img-fluid"></p>
</section>
<section id="extra-extra---qiskit-transpiler-profiling" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="extra-extra---qiskit-transpiler-profiling">Extra Extra - Qiskit Transpiler Profiling</h4>
<p>Qiskit nicely provides a callback hook to capture the impact of various passes, including time spent on passes. This is a nice domain-specific companion to the general profiling results presented here. Running this <a href="https://github.com/bachase/quantum-compiler-profiling/blob/edebf4b8848321cfaec834226f5e5719d2f2fedc/main.py#L10">extra code</a>, we see <sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Qiskit has both analysis passes and transformation passes. The former calculates some properties of the DAG, but doesn’t modify it. The latter does modify it. For simplifying this table, I’ve excluded analysis passes as they didn’t have much runtime in this example.</p></div></div><table class="caption-top table">
<colgroup>
<col style="width: 45%">
<col style="width: 16%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Pass</th>
<th style="text-align: right;">Time (s)</th>
<th style="text-align: right;">Size</th>
<th style="text-align: right;">Depth</th>
<th style="text-align: right;">2Q Gates</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">UnitarySynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">25100</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="even">
<td style="text-align: left;">HighLevelSynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">25100</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="odd">
<td style="text-align: left;">BasisTranslator</td>
<td style="text-align: right;">0.0004</td>
<td style="text-align: right;">25100</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="even">
<td style="text-align: left;">ElidePermutations</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">25100</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RemoveDiagonalGatesBeforeMeasure</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">25100</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="even">
<td style="text-align: left;">RemoveIdentityEquivalent</td>
<td style="text-align: right;">0.0006</td>
<td style="text-align: right;"><strong>15380</strong></td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">10050</td>
</tr>
<tr class="odd">
<td style="text-align: left;">InverseCancellation</td>
<td style="text-align: right;">0.001</td>
<td style="text-align: right;"><strong>8900</strong></td>
<td style="text-align: right;">796</td>
<td style="text-align: right;"><strong>3570</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">ContractIdleWiresInControlFlow</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">8900</td>
<td style="text-align: right;">796</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CommutativeCancellation</td>
<td style="text-align: right;"><strong>0.0118</strong></td>
<td style="text-align: right;"><strong>7289</strong></td>
<td style="text-align: right;"><strong>698</strong></td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">ConsolidateBlocks</td>
<td style="text-align: right;">0.0035</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Split2QUnitaries</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">UnitarySynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">HighLevelSynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">BasisTranslator</td>
<td style="text-align: right;">0.0006</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MinimumPoint</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">ConsolidateBlocks</td>
<td style="text-align: right;">0.0035</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">UnitarySynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">RemoveIdentityEquivalent</td>
<td style="text-align: right;">0.0001</td>
<td style="text-align: right;">7289</td>
<td style="text-align: right;">698</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Optimize1qGatesDecomposition</td>
<td style="text-align: right;">0.0012</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">CommutativeCancellation</td>
<td style="text-align: right;">0.0056</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ContractIdleWiresInControlFlow</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">MinimumPoint</td>
<td style="text-align: right;"><strong>0.0483</strong></td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ConsolidateBlocks</td>
<td style="text-align: right;">0.0035</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">UnitarySynthesis</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RemoveIdentityEquivalent</td>
<td style="text-align: right;">0.0001</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">Optimize1qGatesDecomposition</td>
<td style="text-align: right;">0.0012</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CommutativeCancellation</td>
<td style="text-align: right;">0.0057</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="even">
<td style="text-align: left;">ContractIdleWiresInControlFlow</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MinimumPoint</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7189</td>
<td style="text-align: right;">696</td>
<td style="text-align: right;">3570</td>
</tr>
</tbody>
</table>
<p>For each column, rows in <strong>bold</strong> had meaningful time duration or change in circuit metric. The most meaningful passes are</p>
<section id="removeidentityequivalent" class="level5">
<h5 class="anchored" data-anchor-id="removeidentityequivalent"><a href="https://quantum.cloud.ibm.com/docs/en/api/qiskit/qiskit.transpiler.passes.RemoveIdentityEquivalent">RemoveIdentityEquivalent</a></h5>
<p>“Removes gates whose effect is close to an identity operation up to a global phase and up to the specified tolerance.” Looking at the QASM, we can directly see many small angle rotations that are close to identity:</p>
<pre><code>rz(pi/2097152);
rz(0) q[14];</code></pre>
<p>This doesn’t change the depth or the number of two qubit gates, but is quite a lot of single qubit gates!</p>
</section>
<section id="inversecancellation" class="level5">
<h5 class="anchored" data-anchor-id="inversecancellation"><a href="https://quantum.cloud.ibm.com/docs/en/api/qiskit/qiskit.transpiler.passes.InverseCancellation">InverseCancellation</a></h5>
<p>“Cancel specific Gates which are inverses of each other when they occur back-to-back.” The only reduction in two-qubit gates! Doing nothing is always easier than doing gates that end up doing nothing! After the prior pass, these opportunities are successive cnots on the same qubits:</p>
<pre><code>cx q[99],q[79];
cx q[99],q[79];</code></pre>
</section>
<section id="commutativecancellation" class="level5">
<h5 class="anchored" data-anchor-id="commutativecancellation"><a href="https://quantum.cloud.ibm.com/docs/en/api/qiskit/qiskit.transpiler.passes.CommutativeCancellation">CommutativeCancellation</a></h5>
<p>“Cancel the redundant (self-adjoint) gates through commutation relations.” This is the first reduction in gate depth and comes from being able to push gates around via commutation relations and then cancel them once close together. There’s not a local QASM excerpt to show for this conveniently. But looking at the Rust <a href="https://github.com/Qiskit/qiskit/blob/d595578b62e10f47b6f2515a9cdd687b898ac9e4/crates/transpiler/src/passes/commutation_cancellation.rs">implementation</a>, it looks like this pass treats each qubit as a wire, and then for commuting sets, pushes gates around into a canonical ordering (when they have well defined commutation relations), after which it then combines or cancels gates, replacing with a consolidated gate.</p>
</section>
</section>
</section>
</section>
<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<p>Only a quarter of the runtime was spent in actual transpilation. The rest was in importing Qiskit itself, and parsing the QASM.</p>
<p>You can see the power of the rust Rewrites in e.g.&nbsp;parsing qasm to bytecode. But you can also see the rewrite in progress, where some overhead going back and forth between Python and Rust, and the Python memory model influencing things like copying a DAG.</p>
<p>For transpilation, most <em>time</em> was spent copying the Dag once a fixed point was reached on the optimization pass. By looking at Qiskit specific profiling output via a callback, we saw the few passes that had the largest impact on improvements. Most were applying fairly straightforward simplifications – but those have a big impact on the size, depth and ultimate number of two-qubit gates!</p>


</section>


 ]]></description>
  <guid>https://bachase.github.io/posts/profiling-quantum-compilers-qiskit/</guid>
  <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Profiling Quantum Compilers: Introduction</title>
  <link>https://bachase.github.io/posts/profiling-quantum-compilers/</link>
  <description><![CDATA[ 




<p>As part of my work on <a href="https://github.com/unitaryfoundation/ucc"><code>ucc</code></a>, I’ve spent most of my time to date on benchmarking. In the companion repository <a href="https://github.com/unitaryfoundation/ucc-bench"><code>ucc-bench</code></a>, we’ve collected a small suite of representative circuits and built tooling to automate benchmarking performance of quantum compilers, especially as new versions are released.</p>
<p>Recently, my focus has shifted more toward the internals of quantum compilation, and I wanted to get a deeper understanding of how these compilers actually work. I’ve read papers and stepped through code with a debugger, but the performance angle has been nagging at me. We’re seeing a trend of moving core compiler optimization passes to high-performance languages like Rust <sup>1</sup>, so I figured a great way to learn why is to see where today’s compilers spend their time. By profiling a compiler on a benchmark circuit, we can gain insight into both architecture and performance bottlenecks.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Notably <a href="https://medium.com/qiskit/new-weve-started-using-rust-in-qiskit-for-better-performance-a3676433ca8c">Qiskit</a> and <a href="https://github.com/CQCL/tket2">tket</a></p></div></div><p>This is the first post in a series where I’ll explore the performance of quantum compilers by putting them under the profiler.</p>
<section id="profiling-quantum-compilers" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="profiling-quantum-compilers">Profiling Quantum Compilers</h2>
<p>In this post, I briefly introduce profiling Python with the amazing <a href="https://github.com/benfred/py-spy"><code>py-spy</code></a> tool. I won’t go into exhaustive detail on profiling, but I want to provide just enough background (by way of an example) to understand the results in later posts. I’ll also give a brief overview of the repository that contains the code and scripts used to generate the compiler profiling data.</p>
<section id="profiling-and-py-spy" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="profiling-and-py-spy">Profiling and py-spy</h3>
<p>Profiling is the analysis of a program’s execution to understand where it’s spending its resources. For our purposes, we care about one primary resource: time. We want to know which functions are making the compiler slow.</p>
<p><a href="https://github.com/benfred/py-spy"><code>py-spy</code></a> is a fantastic sampling profiler for Python with minimal overhead. It captures a sample of a running program’s call stack at a regular frequency (say 100 times per second). By aggregating thousands of these samples, <code>py-spy</code> builds a statistical picture of where the program spends its time. A crucial feature for our work is the <code>--native</code> flag<sup>2</sup>. This lets <code>py-spy</code> record non-Python parts of the call stack, letting us look inside the compilers that mix Python with native code.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Unfortunately, <code>--native</code> is only <a href="https://www.benfrederickson.com/profiling-native-python-extensions-with-py-spy/">supported</a> on linux/windows and not my Mac :(. That’s why I used Github codespaces below.</p></div></div><section id="an-example" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="an-example">An example</h4>
<p>Let’s look at an example adapted from a <a href="https://yosefk.com/blog/how-profilers-lie-the-cases-of-gprof-and-kcachegrind.html">classic post</a> on how profilers can be misleading. Turns out modern sampling profilers like <code>py-spy</code> handle the issue in that post, but its a good way to explore the visualizations <code>py-spy</code> generates.</p>
<p>Consider this Python script</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> work(n):</span>
<span id="cb1-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This is a stand-in for a real computational task.</span></span>
<span id="cb1-3">    i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb1-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> n:</span>
<span id="cb1-5">        i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> easy_task():</span>
<span id="cb1-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A task that calls 'work' with a small input.</span></span>
<span id="cb1-9">    work(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100_000</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hard_task():</span>
<span id="cb1-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A task that calls 'work' with a much larger input.</span></span>
<span id="cb1-13">    work(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1_000_000</span>)</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main():</span>
<span id="cb1-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>:</span>
<span id="cb1-17">        easy_task()</span>
<span id="cb1-18">        hard_task()</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb1-21">    main()</span></code></pre></div>
<p>In this code, both <code>easy_task()</code> and <code>hard_task()</code> call the same function, <code>work()</code>, but with vastly different workloads. A simpler profiler that only tracks how much time is spent on specific lines of code would just tell us <code>work()</code> is slow, but not why. A sampling profiler like <code>py-spy</code>, by virtue of collecting the entire call stacks, tells us both where the program is but also how it got there. This means it can distinguish call paths that get to <code>work()</code>, differentiating calls that come by way of <code>easy_task()</code> vs <code>hard_task()</code>.</p>
<p>Let’s see this in action. Assuming the above is saved to a <code>main.py</code>, you would run<sup>3</sup> the command below for a few seconds and then kill the process:</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;On my mac, I need to run this as <code>sudo</code> for <code>py-spy</code> to be able to introspect the running process. I didn’t use <code>--native</code> since this is pure python.</p></div></div><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span>  py-spy record <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--format</span> speedscope <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> profile.json <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--function</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--</span> python main.py</span></code></pre></div>
<p>Here, we tell <code>py-spy</code> to record a profile of <code>python main.py</code> and save it to the file <code>profile.json</code><sup>4</sup>. It uses the <code>speedscope</code> format, which you can upload to <a href="http://speedscope.app/">http://speedscope.app/</a> to visualize.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;I also passed <code>--function</code> to aggregate samples by the first line number of a function versus the sampled number. This way whether the sample is taken when we are at the <code>i+=1</code> or the <code>while i &lt;n:</code> line in <code>work()</code>, the profile result groups them together. If we didn’t do this, the visualization would end up creating an entry for each distinct line-number of <code>work()</code> sampled and make it harder to analyze the charts.</p></div></div><p>Let’s walk through the speedscope <a href="https://www.speedscope.app/#profileURL=https%3A%2F%2Fbachase.github.io%2Fposts%2Fprofiling-quantum-compilers%2Fprofile.json&amp;title=Example%20Profile">view</a> of these results:</p>
<section id="time-order-view" class="level5 page-columns page-full">
<h5 class="anchored" data-anchor-id="time-order-view">Time Order View</h5>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers/time_ordered.png" class="img-fluid"> This is the default view when you first load the profile in speedscope. Time flows from left to right, and along the bottom, you see the the call stack at each point in time. So the blue bar with <code>main()</code> covers the entire view, then beneath it you see the alternating calls of <code>hard_task()</code> and <code>easy_task()</code> (although easy is too narrow to see its name!). The width of each box corresponds to the CPU time of that function call<sup>5</sup>. Mousing over a function creates a pop-up with the specific duration and source file for that call. Clicking on a function opens a call-stack view at the bottom, and shows time spent on this specific instance of the function call and aggregate time spent on all such function calls. There’s not a ton more to glean from this simple example, since the code is small enough that we already know a lot about its execution.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;That is, the time spent in that function call and it’s descendant calls. This might be much longer than the time spent actually in that function itself (the self-time) if it mostly calls into other functions.</p></div></div><p>For more complex applications, the time ordered view is a great way to understand the flow of the program, where wider rectangles guide you to the longer running parts of the program. I find it useful to start with this view to confirm your profile captured what you intended, and then to orient yourself around “goldilocks” function calls. These are functions that aren’t super deep in the call stack that its unclear how you got there, but are also not too high-level that they are basically the whole program. Somewhere in the middle is just right.</p>
</section>
<section id="left-heavy-view" class="level5">
<h5 class="anchored" data-anchor-id="left-heavy-view">Left Heavy View</h5>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers/left_heavy.png" class="img-fluid"></p>
<p>The left heavy view throws out the time-ordered aspects, groups similar call stacks together, and then puts the heavier (longest running) stacks to the left of the plot. It has the same mouse-over and click details as the time-order view. Use this view to see where the program is spending its time overall, regardless of the order of execution. For this example, it nicely shows most time in <code>main()</code> is spent on <code>hard_task()</code> vs <code>easy_task()</code>, even though there are corresponding calls to <code>work()</code> below each. This view is useful when there are lots of interleaved function calls but you just care about the aggregate time spent in each alternate.</p>
</section>
<section id="sandwich-view" class="level5">
<h5 class="anchored" data-anchor-id="sandwich-view">Sandwich View</h5>
<p>This last view has two useful aspects. The first is the table in the image above. This shows the total time and self-time spent in a function call, and as a percent of the entire profile result.</p>
<section id="two-times" class="level6">
<h6 class="anchored" data-anchor-id="two-times">Two Times</h6>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers/sandwich.png" class="img-fluid"> Functions with large/large percent of self-time are hotspots to focus on for optimization. Self-time means the CPU is busy working directly in that function, so you can consider zooming in and doing some micro-benchmarking and optimizations on just that function. For our simple example, it nicely shows that the CPU is really spending its time in that silly loop in <code>work()</code>. If that were real code though, finding a way to optimize it would nicely improve overall performance.</p>
<p>Functions with large/large percent of total-time indicate the primary paths of program execution. This is the total CPU time spent where this function was somewhere in the call stack, but not necessarily where the program was running when sampled. So by definition, <code>main()</code> and other high-level functions have large percentages, but that doesn’t really help you understand much. Instead, you would want to scroll down this list to get to the aforementioned goldilocks level. For me, this is when I get to a function and go “huh, I’m surprised it spent that much time here”. For our simple example, we see that <code>hard_task</code> is indeed ten times heavier than <code>easy_task</code>.</p>
</section>
<section id="the-actual-sandwich" class="level6">
<h6 class="anchored" data-anchor-id="the-actual-sandwich">🥪🥪🥪🥪🥪🥪🥪 (the actual sandwich)</h6>
<p><img src="https://bachase.github.io/posts/profiling-quantum-compilers/sandwich-click.png" class="img-fluid"> If you click on a row in this list, you get the sandwich view shown above. This view splits the timeline around that function, effectively filtering the full time-ordered view to just callers and callees of that function. Not suprisingly, this is useful to zoom in on a function and get a sense of where it falls in the program execution. I find this especially useful to understand the architecture of the program.</p>
</section>
</section>
</section>
</section>
<section id="setup" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>With that whirlwind tour of profiling behind us, how will we explore quantum compilers? <a href="https://github.com/bachase/quantum-compiler-profiling">https://github.com/bachase/quantum-compiler-profiling</a> is a repository with all you need!</p>
<p>The code uses a 100-qubit QFT circuit in <a href="https://github.com/unitaryfoundation/ucc-bench"><code>ucc-bench</code></a> (by way of <a href="https://github.com/Qiskit/benchpress">benchpress</a> and <a href="https://github.com/pnnl/QASMBench">QASMBench</a>). The script in <code>main.py</code> then transpiles/compiles this circuit via <a href="https://www.ibm.com/quantum/qiskit">Qiskit</a>, <a href="https://github.com/unitaryfoundation/ucc"><code>ucc</code></a>, <a href="https://docs.quantinuum.com/tket/api-docs/index.html">pytket</a>, <a href="https://quantumai.google/cirq">Cirq</a>, or <a href="https://pypi.org/project/pyqpanda3/">pyqpanda3</a>. There’s a corresponding <code>run_bench.sh</code> to generate the profiles using <code>py-spy</code>, and there are sub-directories with some profiles checked in<sup>6</sup>. I generated these profiles under a GitHub codespace (which you can do yourself by forking within GitHub). A tad more detail is in the <code>README</code>, but the upshot is we will use speedscope to explore each compiler’s results in the <a href="https://github.com/bachase/quantum-compiler-profiling/tree/main/native.profiles"><code>native.profiles</code></a> directory in future posts.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;I ran profiles with &amp; without <code>--function</code> to aggregate samples to start of functions. I don’t a priori know much about each function. Some might be lengthy with lots of internal loops, so I’d rather keep samples of different lines separate to potentially identify that structure. But having the aggregated view with <code>--function</code> will also help coarse grain over those details when first analyzing results.</p></div></div><p>The QFT circuit was chosen based in recent <code>ucc-bench</code> <a href="https://github.com/unitaryfoundation/ucc-bench/blob/main/results/ucc-benchmarks-8-core-U22.04/compilation_benchmarks/20250819/20250819125708.eca4a630a31567ea794b1e8f90d5038928110223.compilation.csv">performance results</a>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 15%">
<col style="width: 20%">
<col style="width: 19%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Compiler</th>
<th>benchmark_id</th>
<th>raw_multiq_gates</th>
<th>compile_time_ms</th>
<th>compiled_multiq_gates</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ucc</td>
<td>qft</td>
<td>10050</td>
<td>478.4261</td>
<td>2740</td>
</tr>
<tr class="even">
<td>pytket-peep</td>
<td>qft</td>
<td>10050</td>
<td>48776.9968</td>
<td>4498</td>
</tr>
<tr class="odd">
<td>qiskit-default</td>
<td>qft</td>
<td>10050</td>
<td>509.0576</td>
<td>3570</td>
</tr>
<tr class="even">
<td>cirq</td>
<td>qft</td>
<td>10050</td>
<td>32392.2503</td>
<td>4648</td>
</tr>
<tr class="odd">
<td>pyqpanda3</td>
<td>qft</td>
<td>10050</td>
<td>130.838</td>
<td>2740</td>
</tr>
</tbody>
</table>
<p>There is some reduction in two-qubit gates, and the circuit takes a non-trivial amount of compile time. So something interesting is happening!</p>
<p><em>AI Disclaimer</em>: I’ve used LLMs to review and give feedback on this post, but the original content was written by me.</p>


</section>
</section>


 ]]></description>
  <guid>https://bachase.github.io/posts/profiling-quantum-compilers/</guid>
  <pubDate>Thu, 21 Aug 2025 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
